@article{grover2018learning,
  title={Learning policy representations in multiagent systems},
  author={Grover, Aditya and Al-Shedivat, Maruan and Gupta, Jayesh K and Burda, Yura and Edwards, Harrison},
  journal={arXiv preprint arXiv:1806.06464},
  year={2018}
}
@article{tacchetti2018relational,
  title={Relational Forward Models for Multi-Agent Learning},
  author={Tacchetti, Andrea and Song, H Francis and Mediano, Pedro AM and Zambaldi, Vinicius and Rabinowitz, Neil C and Graepel, Thore and Botvinick, Matthew and Battaglia, Peter W},
  journal={arXiv preprint arXiv:1809.11044},
  year={2018}
}
@inproceedings{he2016opponent,
  title={Opponent modeling in deep reinforcement learning},
  author={He, He and Boyd-Graber, Jordan and Kwok, Kevin and Daum{\'e} III, Hal},
  booktitle={International Conference on Machine Learning},
  pages={1804--1813},
  year={2016}
}
@article{schoenmakers2007fictitious,
  title={Fictitious play in stochastic games},
  author={Schoenmakers, Gijs and Flesch, J{\'a}nos and Thuijsman, Frank},
  journal={Mathematical Methods of Operations Research},
  volume={66},
  number={2},
  pages={315--325},
  year={2007},
  publisher={Springer}
}
@article{shamma2005dynamic,
  title={Dynamic fictitious play, dynamic gradient play, and distributed convergence to Nash equilibria},
  author={Shamma, Jeff S and Arslan, G{\"u}rdal},
  journal={IEEE Transactions on Automatic Control},
  volume={50},
  number={3},
  pages={312--327},
  year={2005},
  publisher={IEEE}
}
@article{monderer1996fictitious,
  title={Fictitious play property for games with identical interests},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Journal of Economic Theory},
  volume={68},
  number={1},
  pages={258--265},
  year={1996},
  publisher={Elsevier}
}
@article{brown1951iterative,
  title={Iterative solution of games by fictitious play},
  author={Brown, George W},
  journal={Activity Analysis of Production and Allocation},
  volume={13},
  number={1},
  pages={374--376},
  year={1951},
  publisher={New York}
}
@book{myerson2013game,
  title={Game Theory},
  author={Myerson, Roger B},
  year={2013},
  publisher={Harvard University Press}
}
@inproceedings{hansen2004dynamic,
  title={Dynamic programming for partially observable stochastic games},
  author={Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
  booktitle={AAAI},
  volume={4},
  pages={709--715},
  year={2004}
}
@misc{reward_design_quip,
  author = {Kaiqing Zhang},
  title = {Reward Function Design For Multi-Car Racing},
  howpublished = "\url{https://quip-amazon.com/fpfoA9DUYyG1}",
  year = {2019}
} 
@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={International Conference on Machine Learning},
  pages={2817--2826},
  year={2017}
}

@inproceedings{zhang2018fully,
  title={Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents},
  author={Zhang, Kaiqing and Yang, Zhuoran  and Liu, Han and Zhang, Tong and Ba\c{s}ar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5867--5876},
  year={2018}
}  
@inproceedings{zhang18cdc,
  title = 	 {Networked multi-agent reinforcement learning in continuous spaces},
  author = 	 {Zhang, Kaiqing and Yang, Zhuoran and Ba\c{s}ar, Tamer},
  booktitle = 	{Proceedings of the 57th IEEE Conference on Decision and Control},
  pages={2771--2776},
  year = 	 {2018}
}


@article{lin2018solving,
  title={Solving weakly-convex-weakly-concave saddle-point problems as weakly-monotone variational inequality},
  author={Lin, Qihang and Liu, Mingrui and Rafique, Hassan and Yang, Tianbao},
  journal={arXiv preprint arXiv:1810.10207},
  year={2018}
}
@article{grnarova2017online,
  title={An online learning approach to generative adversarial networks},
  author={Grnarova, Paulina and Levy, Kfir Y and Lucchi, Aurelien and Hofmann, Thomas and Krause, Andreas},
  journal={arXiv preprint arXiv:1706.03269},
  year={2017}
}
@inproceedings{mertikopoulos2019optimistic,
  title={Optimistic mirror descent in saddle-point problems: {G}oing the extra (gradient) mile},
  author={Mertikopoulos, Panayotis and Zenati, Houssam and Lecouat, Bruno and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{nagarajan2017gradient,
  title={Gradient descent {GAN} optimization is locally stable},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5585--5595},
  year={2017}
}
@inproceedings{heusel2017gans,
  title={{GANs} trained by a two time-scale update rule converge to a local {N}ash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6626--6637},
  year={2017}
}
@article{cherukuri2017saddle,
  title={Saddle-point dynamics: {C}onditions for asymptotic stability of saddle points},
  author={Cherukuri, Ashish and Gharesifard, Bahman and Cortes, Jorge},
  journal={SIAM Journal on Control and Optimization},
  volume={55},
  number={1},
  pages={486--511},
  year={2017},
  publisher={SIAM}
}
@article{rafique2018non,
  title={Non-convex min-max optimization: {P}rovable algorithms and applications in machine learning},
  author={Rafique, Hassan and Liu, Mingrui and Lin, Qihang and Yang, Tianbao},
  journal={arXiv preprint arXiv:1810.02060},
  year={2018}
}
@article{lu2018understand,
  title={Understand the dynamics of {GANs} via primal-dual optimization},
  author={Lu, Songtao and Singh, Rahul and Chen, Xiangyi and Chen, Yongxin and Hong, Mingyi},
  year={2018}
}
@article{nouiehed2019solving,
  title={Solving a Class of Non-Convex Min-Max Games Using Iterative First Order Methods},
  author={Nouiehed, Maher and Sanjabi, Maziar and Lee, Jason D and Razaviyayn, Meisam},
  journal={arXiv preprint arXiv:1902.08297},
  year={2019}
}
@article{whittle1981risk,
  title={Risk-sensitive linear/quadratic/{G}aussian control},
  author={Whittle, Peter},
  journal={Advances in Applied Probability},
  volume={13},
  number={4},
  pages={764--777},
  year={1981},
  publisher={Cambridge University Press}
}
@article{jacobson1973optimal,
  title={Optimal stochastic linear systems with exponential performance criteria and their relation to deterministic differential games},
  author={Jacobson, David},
  journal={IEEE Transactions on Automatic control},
  volume={18},
  number={2},
  pages={124--131},
  year={1973},
  publisher={IEEE}
}
@inproceedings{chen2017robust,
  title={Robust optimization for non-convex objectives},
  author={Chen, Robert S and Lucier, Brendan and Singer, Yaron and Syrgkanis, Vasilis},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4705--4714},
  year={2017}
}
@article{adolphs2018local,
  title={Local saddle point optimization: {A} curvature exploitation approach},
  author={Adolphs, Leonard and Daneshmand, Hadi and Lucchi, Aurelien and Hofmann, Thomas},
  journal={arXiv preprint arXiv:1805.05751},
  year={2018}
}
@inproceedings{zhang2019policy,
  title={Policy Search in Infinite-Horizon Discounted Reinforcement Learning: Advances through Connections to Non-Convex Optimization},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Ba{\c{s}}ar, Tamer},
  booktitle={Annual Conference on Information Sciences and Systems (CISS)},
  pages={1--3},
  year={2019},
  organization={IEEE}
}
@article{papini2018stochastic,
  title={Stochastic variance-reduced policy gradient},
  author={Papini, Matteo and Binaghi, Damiano and Canonaco, Giuseppe and Pirotta, Matteo and Restelli, Marcello},
  journal={arXiv preprint arXiv:1806.05618},
  year={2018}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}
@article{o2016combining,
  title={Combining policy gradient and Q-learning},
  author={O'Donoghue, Brendan and Munos, Remi and Kavukcuoglu, Koray and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1611.01626},
  year={2016}
}
@book{graham2018kronecker,
  title={Kronecker products and matrix calculus with applications},
  author={Graham, Alexander},
  year={2018},
  publisher={Courier Dover Publications}
}
@book{kwakernaak1972linear,
  title={Linear Optimal Control Systems},
  author={Kwakernaak, Huibert and Sivan, Raphael},
  volume={1},
  year={1972},
  publisher={Wiley-Interscience New York}
}
@book{tyrtyshnikov2012brief,
  title={A Brief Introduction to Numerical Analysis},
  author={Tyrtyshnikov, Eugene E},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{nedic2009subgradient,
  title={Subgradient methods for saddle-point problems},
  author={Nedi{\'c}, Angelia and Ozdaglar, Asuman},
  journal={Journal of Optimization Theory and Applications},
  volume={142},
  number={1},
  pages={205--228},
  year={2009},
  publisher={Springer}
}
@article{nemirovski2004prox,
  title={Prox-method with rate of convergence O (1/t) for variational inequalities with {L}ipschitz continuous monotone operators and smooth convex-concave saddle point problems},
  author={Nemirovski, Arkadi},
  journal={SIAM Journal on Optimization},
  volume={15},
  number={1},
  pages={229--251},
  year={2004},
  publisher={SIAM}
}
@article{fan1953minimax,
  title={Minimax theorems},
  author={Fan, Ky},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  volume={39},
  number={1},
  pages={42},
  year={1953},
  publisher={National Academy of Sciences}
}
@article{sion1958general,
  title={On general minimax theorems.},
  author={Sion, Maurice and others},
  journal={Pacific Journal of Mathematics},
  volume={8},
  number={1},
  pages={171--176},
  year={1958},
  publisher={Pacific Journal of Mathematics}
}
@article{jacobson1977values,
  title={On values and strategies for infinite-time linear quadratic games},
  author={Jacobson, D},
  journal={IEEE Transactions on Automatic Control},
  volume={22},
  number={3},
  pages={490--491},
  year={1977},
  publisher={IEEE}
}
@article{al2007model,
  title={Model-free {Q}-learning designs for linear discrete-time zero-sum games with application to {$\cH$}-infinity control},
  author={Al-Tamimi, Asma and Lewis, Frank L and Abu-Khalaf, Murad},
  journal={Automatica},
  volume={43},
  number={3},
  pages={473--481},
  year={2007},
  publisher={Elsevier}
}
@article{konstantinov1993perturbation,
  title={Perturbation analysis of the discrete {R}iccati equation},
  author={Konstantinov, Michail M and Petkov, P Hr and Christov, Nicolai D},
  journal={Kybernetika},
  volume={29},
  number={1},
  pages={18--29},
  year={1993},
  publisher={Institute of Information Theory and Automation AS CR}
}
@article{sun1998perturbation,
  title={Perturbation theory for algebraic {R}iccati equations},
  author={Sun, Ji-Guang},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={19},
  number={1},
  pages={39--65},
  year={1998},
  publisher={SIAM}
}
@article{cartis2010complexity,
  title={On the complexity of steepest descent, {N}ewton's and regularized {N}ewton's methods for nonconvex unconstrained optimization problems},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Ph L},
  journal={SIAM Journal on Optimization},
  volume={20},
  number={6},
  pages={2833--2852},
  year={2010},
  publisher={SIAM}
} 
@article{khamaru2018convergence,
  title={Convergence guarantees for a class of non-convex and non-smooth optimization problems},
  author={Khamaru, Koulik and Wainwright, Martin J},
  journal={arXiv preprint arXiv:1804.09629},
  year={2018}
}
@article{magnus1985matrix,
  title={Matrix differential calculus with applications to simple, {H}adamard, and {K}ronecker products},
  author={Magnus, Jan R and Neudecker, Heinz},
  journal={Journal of Mathematical Psychology},
  volume={29},
  number={4},
  pages={474--492},
  year={1985},
  publisher={Elsevier}
}
@book{krantz2012implicit,
  title={The implicit function theorem: History, theory, and applications},
  author={Krantz, Steven G and Parks, Harold R},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@book{bertsekas2005dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P.},
  volume={1},
  number={2},
  year={2005},
  publisher={Athena Scientific Belmont, MA}
}
@book{zhou1996robust,
  title={Robust and Optimal control},
  author={Zhou, Kemin and Doyle, John Comstock and Glover, Keith and others},
  volume={40},
  year={1996},
  publisher={Prentice Hall New Jersey}
}
@article{ran1993linear,
  title={Linear quadratic problems with indefinite cost for discrete time systems},
  author={Ran, ACM and Trentelman, Harry L},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={14},
  number={3},
  pages={776--797},
  year={1993},
  publisher={SIAM}
}
@article{cartis2017worst,
  title={Worst-case evaluation complexity and optimality of second-order methods for nonconvex smooth optimization},
  author={Cartis, Coralia and Gould, Nick IM and Toint, Philippe L},
  journal={arXiv preprint arXiv:1709.07180},
  year={2017}
}
@book{nesterov2013introductory, 
  title={Introductory Lectures on Convex Optimization: {A} Basic Course},
  author={Nesterov, Yurii},
  volume={87},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@article{sanjabi2018solving,
  title={Solving Non-Convex Non-Concave Min-Max Games Under {P}olyak-{$\L$}ojasiewicz Condition},
  author={Sanjabi, Maziar and Razaviyayn, Meisam and Lee, Jason D},
  journal={arXiv preprint arXiv:1812.02878},
  year={2018}
}
@article{stoorvogel1994discrete,
  title={The discrete-time {R}iccati equation related to the $\mathcal{H}_{\infty}$ control problem},
  author={Stoorvogel, Anton A and Weeren, Arie JTM},
  journal={IEEE Transactions on Automatic Control},
  volume={39}, 
  number={3},
  pages={686--691},
  year={1994},
  publisher={IEEE}
}
@article{fazel2018global,
  title={Global Convergence of Policy Gradient Methods for Linearized Control Problems},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham M and Mesbahi, Mehran},
  journal={arXiv preprint arXiv:1801.05039},
  year={2018}
}
@book{bacsar2008h,
  title={$\mathcal{H}_\infty$ Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach},
  author={Ba{\c{s}}ar, Tamer and Bernhard, Pierre},
  year={2008},
  publisher={Springer Science \& Business Media}
}
@article{movric2014cooperative,
  title={Cooperative optimal control for multi-agent systems on directed graph topologies},
  author={Movric, Kristian Hengster and Lewis, Frank L},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={3},
  pages={769--774},
  year={2014},
  publisher={IEEE}
}
@book{lewis2013cooperative,
  title={Cooperative control of multi-agent systems: Optimal and adaptive design approaches},
  author={Lewis, Frank L and Zhang, Hongwei and Hengster-Movric, Kristian and Das, Abhijit},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@article{cao2013overview,
  title={An overview of recent progress in the study of distributed multi-agent coordination},
  author={Cao, Yongcan and Yu, Wenwu and Ren, Wei and Chen, Guanrong},
  journal={IEEE Transactions on Industrial Informatics},
  volume={9},
  number={1},
  pages={427--438},
  year={2013},
  publisher={IEEE}
}
@article{dall2013distributed,
  title={Distributed optimal power flow for smart microgrids},
  author={Dall'Anese, Emiliano and Zhu, Hao and Giannakis, Georgios B},
  journal={IEEE Transactions on Smart Grid},
  volume={4},
  number={3},
  pages={1464--1475},
  year={2013},
  publisher={IEEE}
}
@inproceedings{rabbat2004distributed,
  title={Distributed optimization in sensor networks},
  author={Rabbat, Michael and Nowak, Robert},
  booktitle={International Symposium on Information Processing in Sensor Networks},
  pages={20--27},
  year={2004}
}
@article{benaim1999dynamics,
  title={Dynamics of stochastic approximation algorithms},
  author={Bena{\"\i}m, Michel},
  journal={S{\'e}minaire de Probabilit{\'e}s, XXXIII},
  volume={1709},
  pages={1--68},
  year={1999},
  publisher={Springer Berlin, Germany}
}
@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: A hierarchical \relax{B}ayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={International Conference on Machine Learning},
  pages={1015--1022},
  year={2007}
}
@article{parisotto2015actor,
  title={Actor-mimic: Deep multi-task and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}
@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multi-agent Systems},
  pages={66--83},
  year={2017}
}
@article{kapetanakis2002reinforcement,
  title={Reinforcement learning of coordination in cooperative multi-agent systems},
  author={Kapetanakis, Spiros and Kudenko, Daniel},
  journal={American Association for Artificial Intelligence/Innovative Applications of Artificial Intelligence Conferences},
  volume={2002},
  pages={326--331},
  year={2002}
}
@article{nedich2016achieving,
  title={Achieving geometric convergence for distributed optimization over time-varying graphs},
  author={Nedich, Angelia and Olshevsky, Alex and Shi, Wei},
  journal={arXiv preprint arXiv:1607.03218},
  year={2016}
}
@article{kar2010distributed,
  title={Distributed consensus algorithms in sensor networks: Quantized data and random link failures},
  author={Kar, Soummya and Moura, Jos{\'e} MF},
  journal={IEEE Transactions on Signal Processing},
  volume={58},
  number={3},
  pages={1383--1400},
  year={2010},
  publisher={IEEE}
}
@article{metivier1984applications,
  title={Applications of a \relax{K}ushner and \relax{C}lark lemma to general classes of stochastic algorithms},
  author={Metivier, Michel and Priouret, Pierre},
  journal={IEEE Transactions on Information Theory},
  volume={30},
  number={2},
  pages={140--151},
  year={1984},
  publisher={IEEE}
}
@book{kushner1978stochastic,
  title={Stochastic approximation methods for constrained and unconstrained systems},
  author={Kushner, Harold Joseph and Clark, Dean S},
  publisher={Springer Science \& Business Media},
  year={1978}
}
@book{neveu1975discrete,
  title={Discrete-parameter martingales},
  author={Neveu, Jacques},
  year={1975},
  publisher={Elsevier}
}
@article{dann2014policy,
  title={Policy evaluation with temporal differences: A survey and comparison},
  author={Dann, Christoph and Neumann, Gerhard and Peters, Jan and others},
  journal={Journal of Machine Learning Research},
  volume={15},
  pages={809--883},
  year={2014},
  publisher={Massachusetts Institute of Technology Press (MIT Press)/Microtome Publishing}
}
@book{hall2014martingale,
  title={Martingale limit theory and its application},
  author={Hall, Peter and Heyde, Christopher C},
  year={2014},
  publisher={Academic press}
}
@article{cattivelli2008diffusion,
  title={Diffusion recursive least-squares for distributed estimation over adaptive networks},
  author={Cattivelli, Federico S and Lopes, Cassio G and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={56},
  number={5},
  pages={1865--1877},
  year={2008},
  publisher={IEEE}
}
@inproceedings{xiao2005scheme,
  title={A scheme for robust distributed sensor fusion based on average consensus},
  author={Xiao, Lin and Boyd, Stephen and Lall, Sanjay},
  booktitle={International Symposium on Information Processing in Sensor Networks},
  pages={9},
  year={2005}
}
@article{mathkar2016nonlinear,
  title={Nonlinear gossip},
  author={Mathkar, Adwaitvedant S and Borkar, Vivek S},
  journal={SIAM Journal on Control and Optimization},
  volume={54},
  number={3},
  pages={1535--1557},
  year={2016},
  publisher={SIAM}
}
@article{andrieu2005stability,
  title={Stability of stochastic approximation under verifiable conditions},
  author={Andrieu, Christophe and Moulines, {\'E}ric and Priouret, Pierre},
  journal={SIAM Journal on Control and Optimization},
  volume={44},
  number={1},
  pages={283--312},
  year={2005},
  publisher={SIAM}
}
@article{borkar2000ode,
  title={The \relax{ODE} method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

@article{hu2003nash,
  title={Nash {Q}-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of Machine Learning Research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}

@article{tsitsiklis1999average,
  title={Average cost temporal-difference learning},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={Automatica},
  volume={35},
  number={11},
  pages={1799--1808},
  year={1999},
  publisher={Elsevier}
}
@article{abounadi2001learning,
  title={Learning algorithms for \relax{M}arkov \relax{D}ecision \relax{P}rocesses with average cost},
  author={Abounadi, Jinane and Bertsekas, D and Borkar, Vivek S},
  journal={SIAM Journal on Control and Optimization},
  volume={40},
  number={3},
  pages={681--698},
  year={2001},
  publisher={SIAM}
}
@article{chen2012diffusion,
  title={Diffusion adaptation strategies for distributed optimization and learning over networks},
  author={Chen, Jianshu and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={60},
  number={8},
  pages={4289--4305},
  year={2012},
  publisher={IEEE}
}
@article{boyd2011distributed,
  title={Distributed optimization and statistical learning via the alternating direction method of multipliers},
  author={Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={3},
  number={1},
  pages={1--122},
  year={2011},
  publisher={Now Publishers Inc.}
}
@article{tsitsiklis1986distributed,
  title={Distributed asynchronous deterministic and stochastic gradient optimization algorithms},
  author={Tsitsiklis, John and Bertsekas, Dimitri and Athans, Michael},
  journal={IEEE Transactions on Automatic Control},
  volume={31},
  number={9},
  pages={803--812},
  year={1986},
  publisher={IEEE}
}
@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1075--1081},
  year={1997}
}
@article{foerster2017stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Torr, Philip and Kohli, Pushmeet and Whiteson, Shimon and others},
  journal={arXiv preprint arXiv:1702.08887},
  year={2017}
}
@article{lowe2017multi,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:1706.02275},
  year={2017}
}
@inproceedings{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Yannis M and de Freitas, Nando and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2137--2145},
  year={2016}
}
@article{hu2003nash,
  title={Nash \relax{Q}-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of Machine Learning Research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}
@article{lanctot2017unified,
  title={A unified game-theoretic approach to multi-agent reinforcement learning},
  author={Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and P{\'e}rolat, Julien and Silver, David and Graepel, Thore},
  journal={arXiv preprint arXiv:1711.00832},
  year={2017}
}
@article{arslan2017decentralized,
  title={Decentralized \relax{Q}-Learning for Stochastic Teams and Games},
  author={Arslan, G{\"u}rdal and Y{\"u}ksel, Serdar},
  journal={IEEE Transactions on Automatic Control},
  volume={62},
  number={4},
  pages={1545--1558},
  year={2017},
  publisher={IEEE}
}
@inproceedings{lauer2000algorithm,
  title={An algorithm for distributed reinforcement learning in cooperative multi-agent systems},
  author={Lauer, Martin and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning},
  year={2000}
  }
@article{littman2001value,
  title={Value-function reinforcement learning in \relax{M}arkov games},
  author={Littman, Michael L},
  journal={Cognitive Systems Research},
  volume={2},
  number={1},
  pages={55--66},
  year={2001},
  publisher={Elsevier}
}

@inproceedings{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={157--163},
  year={1994},
}


@inproceedings{wang2003reinforcement,
  title={Reinforcement learning to play an optimal \relax{N}ash equilibrium in team \relax{M}arkov games},
  author={Wang, Xiaofeng and Sandholm, Tuomas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1603--1610},
  year={2003}
}
@article{teh2017distral,
  title={Distral: Robust multi-task reinforcement learning},
  author={Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1707.04175},
  year={2017}
}
@inproceedings{omidshafiei2017deep,
  title={Deep decentralized multi-task multi-agent reinforcement learning under partial observability},
  author={Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P and Vian, John},
  booktitle={International Conference on Machine Learning},
  pages={2681--2690},
  year={2017}
}

@article{shoham2003multi,
  title={Multi-agent reinforcement learning: A critical survey},
  author={Shoham, Yoav and Powers, Rob and Grenager, Trond},
  year={2003},
  journal={Technical \relax{Report}}
}
@inproceedings{boutilier1996planning,
  title={Planning, learning and coordination in multi-agent decision processes},
  author={Boutilier, Craig},
  booktitle={Conference on Theoretical Aspects of Rationality and Knowledge},
  pages={195--210},
  year={1996}
}
@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={873--881},
  year={2011}
}  
@article{ram2010distributed,
  title={Distributed stochastic subgradient projection algorithms for convex optimization},
  author={Ram, S Sundhar and Nedi{\'c}, Angelia and Veeravalli, Venugopal V},
  journal={Journal of Optimization Theory and Applications},
  volume={147},
  number={3},
  pages={516--545},
  year={2010},
  publisher={Springer}
}
@article{tu2012diffusion,
  title={Diffusion strategies outperform consensus strategies for distributed estimation over adaptive networks},
  author={Tu, Sheng-Yuan and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={60},
  number={12},
  pages={6217--6234},
  year={2012},
  publisher={IEEE}
}
@article{nedic2009distributed,
  title={Distributed subgradient methods for multi-agent optimization},
  author={Nedic, Angelia and Ozdaglar, Asuman},
  journal={IEEE Transactions on Automatic Control},
  volume={54},
  number={1},
  pages={48--61},
  year={2009},
  publisher={IEEE}
}
@article{jakovetic2011cooperative,
  title={Cooperative convex optimization in networked systems: Augmented Lagrangian algorithms with directed gossip communication},
  author={Jakovetic, Dusan and Xavier, Joao and Moura, Jos{\'e} MF},
  journal={IEEE Transactions on Signal Processing},
  volume={59},
  number={8},
  pages={3889--3902},
  year={2011},
  publisher={IEEE}
}
@article{cortes2004coverage,
  title={Coverage control for mobile sensing networks},
  author={Cortes, Jorge and Martinez, Sonia and Karatas, Timur and Bullo, Francesco},
  journal={IEEE Transactions on Robotics and Automation},
  volume={20},
  number={2},
  pages={243--255},
  year={2004},
  publisher={IEEE}
}
@article{callaway2011achieving,
  title={Achieving controllability of electric loads},
  author={Callaway, Duncan S and Hiskens, Ian A},
  journal={Proceedings of the IEEE},
  volume={99},
  number={1},
  pages={184--199},
  year={2011},
  publisher={IEEE}
}
@article{corke2005networked,
  title={Networked robots: Flying robot navigation using a sensor net},
  author={Corke, Peter and Peterson, Ron and Rus, Daniela},
  journal={Robotics \relax{Research}},
  pages={234--243},
  year={2005},
  publisher={Springer}
}
@article{olfati2006flocking,
  title={Flocking for multi-agent dynamic systems: Algorithms and theory},
  author={Olfati-Saber, Reza},
  journal={IEEE Transactions on Automatic Control},
  volume={51},
  number={3},
  pages={401--420},
  year={2006},
  publisher={IEEE}
}
@article{fax2004information,
  title={Information flow and cooperative control of vehicle formations},
  author={Fax, J Alexander and Murray, Richard M},
  journal={IEEE Transactions on Automatic Control},
  volume={49},
  number={9},
  pages={1465--1476},
  year={2004},
  publisher={IEEE}
}
@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@book{puterman2014markov,
  title={Markov \relax{D}ecision \relax{P}rocesses: \relax{D}iscrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}
@article{boyd2006randomized,
	title={Randomized gossip algorithms},
	author={Boyd, Stephen and Ghosh, Arpita and Prabhakar, Balaji and Shah, Devavrat},
	journal={IEEE/ACM Transactions on Networking},
	volume={14},
	number={SI},
	pages={2508--2530},
	year={2006},
	publisher={IEEE Press}
}
@article{aysal2009broadcast,
	title={Broadcast gossip algorithms for consensus},
	author={Aysal, Tuncer Can and Yildiz, Mehmet Ercan and Sarwate, Anand D and Scaglione, Anna},
	journal={IEEE Transactions on Signal Processing},
	volume={57},
	number={7},
	pages={2748--2761},
	year={2009},
	publisher={IEEE}
}
@inproceedings{silver2014deterministic,
	title={Deterministic policy gradient algorithms},
	author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	booktitle={International Conference on Machine Learning},
	pages={387--395},
	year={2014}
}
@article{peters2008reinforcement,
	title={Reinforcement learning of motor skills with policy gradients},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neural networks},
	volume={21},
	number={4},
	pages={682--697},
	year={2008},
	publisher={Elsevier}
}
@article{baxter2001infinite,
	title={Infinite-horizon policy-gradient estimation},
	author={Baxter, Jonathan and Bartlett, Peter L},
	journal={Journal of Artificial Intelligence Research},
	volume={15},
	pages={319--350},
	year={2001}
}
@inproceedings{melo2008analysis,
	title={An analysis of reinforcement learning with function approximation},
	author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
	booktitle={International Conference on Machine Learning},
	pages={664--671},
	year={2008},
	organization={ACM}
}




@inproceedings{baird1995residual,
	title={Residual algorithms: Reinforcement learning with function approximation},
	author={Baird, Leemon and others},
	booktitle={International Conference on Machine Learning},
	pages={30--37},
	year={1995}
}
@book{rummery1994line,
	title={On-line Q-learning using connectionist systems},
	author={Rummery, Gavin A and Niranjan, Mahesan},
	volume={37},
	year={1994},
	publisher={University of Cambridge, Department of Engineering}
}
@article{watkins1992q,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}
@article{schulman2015high,
	title={High-dimensional continuous control using generalized advantage estimation},
	author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1506.02438},
	year={2015}
}
@inproceedings{mnih2016asynchronous,
	title={Asynchronous methods for deep reinforcement learning},
	author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	booktitle={International Conference on Machine Learning},
	pages={1928--1937},
	year={2016}
}
@article{bahdanau2016actor,
	title={An actor-critic algorithm for sequence prediction},
	author={Bahdanau, Dzmitry and Brakel, Philemon and Xu, Kelvin and Goyal, Anirudh and Lowe, Ryan and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1607.07086},
	year={2016}
}
@article{silver2017mastering,
	title={Mastering the game of \relax{G}o without human knowledge},
	author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	journal={Nature},
	volume={550},
	number={7676},
	pages={354--359},
	year={2017},
	publisher={Nature Research}
}
@article{peters2008natural,
	title={Natural actor-critic},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neurocomputing},
	volume={71},
	number={7},
	pages={1180--1190},
	year={2008},
	publisher={Elsevier}
}

@inproceedings{bhatnagar2008incremental,
	title={Incremental natural actor-critic algorithms},
	author={Bhatnagar, Shalabh and Ghavamzadeh, Mohammad and Lee, Mark and Sutton, Richard S},
	booktitle={Advances in Neural Information Processing Systems},
	pages={105--112},
	year={2008}
}
@inproceedings{sutton2000policy,
	title={Policy gradient methods for reinforcement learning with function approximation},
	author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1057--1063},
	year={2000}
}
@book{kushner2003stochastic,
	title={Stochastic approximation and recursive algorithms and applications},
	author={Kushner, Harold J. and Yin, G. George},
	year={2003},
	publisher={Springer, New York, NY}
}



@book{benveniste2012adaptive,
	title={Adaptive algorithms and stochastic approximations},
	author={Benveniste, Albert and M{\'e}tivier, Michel and Priouret, Pierre},
	volume={22},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@book{borkar2008stochastic,
	title={Stochastic approximation: \relax{A} dynamical systems viewpoint},
	author={Borkar, Vivek S},
	journal={Cambridge Books},
	year={2008},
	publisher={Cambridge University Press}
}
@inproceedings{konda2000actor,
	title={Actor-critic algorithms},
	author={Konda, Vijay R and Tsitsiklis, John N},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1008--1014},
	year={2000}
}
@article{bhatnagar2009natural,
	title={Natural actor-critic algorithms},
	author={Bhatnagar, Shalabh and Sutton, Richard and Ghavamzadeh, Mohammad and Lee, Mark},
	journal={Automatica},
	volume={45},
	number={11},
	pages={2471-2482},
	year={2009}
}
@article{bhatnagar2010actor,
	title={An actor--critic algorithm with function approximation for discounted cost constrained \relax{M}arkov \relax{D}ecision \relax{P}rocesses},
	author={Bhatnagar, Shalabh},
	journal={Systems \& Control Letters},
	volume={59},
	number={12},
	pages={760--766},
	year={2010},
	publisher={Elsevier}
}
@inproceedings{sutton2009fast,
	title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
	author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
	booktitle={International Conference on Machine Learning},
	pages={993--1000},
	year={2009},
	organization={ACM}
}

@inproceedings{kakade2002approximately,
  title={Approximately Optimal Approximate Reinforcement Learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={267--274},
  year={2002},
  organization={Morgan Kaufmann Publishers Inc.}
}


@article{hernandez2017survey,
  title={A survey of learning in multiagent environments: Dealing with non-stationarity},
  author={Hernandez-Leal, Pablo and Kaisers, Michael and Baarslag, Tim and de Cote, Enrique Munoz},
  journal={arXiv preprint arXiv:1707.09183},
  year={2017}
}

@inproceedings{degris2012off,
  title={Off-Policy Actor-Critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard},
  booktitle={International Conference on Machine Learning},
  year={2012}
}

 

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}



@article{bianchi2013performance,
	title={Performance of a distributed stochastic approximation algorithm},
	author={Bianchi, Pascal and Fort, Gersende and Hachem, Walid},
	journal={IEEE Transactions on Information Theory},
	volume={59},
	number={11},
	pages={7405--7418},
	year={2013},
	publisher={IEEE}
}
@article{mathkar2017distributed,
  title={Distributed Reinforcement Learning via Gossip},
  author={Mathkar, Adwaitvedant and Borkar, Vivek S},
  journal={IEEE Transactions on Automatic Control},
  volume={62},
  number={3},
  pages={1465--1470},
  year={2017},
  publisher={IEEE}
}
@article{kar2013cal,
	title={\relax {QD}-Learning: A Collaborative Distributed Strategy for Multi-Agent Reinforcement Learning Through  Consensus + Innovations},
	author={Kar, Soummya and Moura, Jos{\'e} MF and Poor, H Vincent},
	journal={IEEE Transactions on Signal Processing},
	volume={61},
	number={7},
	pages={1848--1862},
	year={2013},
	publisher={IEEE}
}
@article{busoniu2008comprehensive,
	title={A comprehensive survey of multi-agent reinforcement learning},
	author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
	journal={IEEE Transactions on Systems, Man, And Cybernetics-Part C: Applications and Reviews, 38 (2), 2008},
	year={2008},
	publisher={IEEE}
}
@article{prasad2014actor,
	title={Actor-Critic Algorithms for Learning \relax{N}ash Equilibria in N-player General-Sum Games},
	author={Prasad, HL and Prashanth, LA and Bhatnagar, Shalabh},
	journal={arXiv preprint arXiv:1401.2086},
	year={2014}
}
@article{macua2015distributed,
	title={Distributed policy evaluation under multiple behavior strategies},
	author={Macua, Sergio Valcarcel and Chen, Jianshu and Zazo, Santiago and Sayed, Ali H},
	journal={IEEE Transactions on Automatic Control},
	volume={60},
	number={5},
	pages={1260--1274},
	year={2015},
	publisher={IEEE}
}
@article{stankovic2016distributed,
	title={Distributed stochastic approximation: weak convergence and network design},
	author={Stankovi{\'c}, Milo{\v{s}} S and Ili{\'c}, Nemanja and Stankovi{\'c}, Srdjan S},
	journal={IEEE Transactions on Automatic Control},
	volume={61},
	number={12},
	pages={4069--4074},
	year={2016},
	publisher={IEEE}
}
@inproceedings{stankovic2016multi,
	title={Multi-agent temporal-difference learning with linear function approximation: Weak convergence under time-varying network topologies},
	author={Stankovi{\'c}, Milo{\v{s}} S and Stankovi{\'c}, Srdjan S},
	booktitle={American Control Conference (ACC), 2016},
	pages={167--172},
	year={2016},
	organization={IEEE}
}


@article{adler2002cooperative,
  title={A cooperative multi-agent transportation management and route guidance system},
  author={Adler, Jeffrey L and Blue, Victor J},
  journal={Transportation Research Part C: Emerging Technologies},
  volume={10},
  number={5},
  pages={433--454},
  year={2002},
  publisher={Elsevier}
}


@article{foerster2017counterfactual,
  title={Counterfactual Multi-Agent Policy Gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1705.08926},
  year={2017}
}




@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}




@article{silver2016mastering,
  title={Mastering the game of \relax{G}o with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}


@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}
@incollection{kober2012reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Peters, Jan},
  booktitle={Reinforcement Learning},
  pages={579--610},
  year={2012},
  publisher={Springer}
}


@article{li2017deep,
  title={Deep reinforcement learning: An overview},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1701.07274},
  year={2017}
}


@article{kok2006collaborative,
  title={Collaborative multi-agent reinforcement learning by payoff propagation},
  author={Kok, Jelle R and Vlassis, Nikos},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={Sep},
  pages={1789--1828},
  year={2006}
}


@article{castro2010convergent,
  title={A convergent online single-time-scale actor-critic algorithm},
  author={Castro, Dotan Di and Meir, Ron},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Jan},
  pages={367--410},
  year={2010}
}


@inproceedings{baxter2000direct,
  title={Direct gradient-based reinforcement learning},
  author={Baxter, Jonathan and Bartlett, Peter L},
  booktitle={International Symposium on Circuits and Systems},
  pages={271--274},
  year={2000}
}


@inproceedings{kakade2002natural,
 title={A natural policy gradient},
 author={Kakade, Sham M},
 booktitle={Advances in Neural Information Processing Systems},
 pages={1531--1538},
 year={2002}
}


@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural Computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}




@inproceedings{wang2016sample,
  title={Sample Efficient Actor-Critic with Experience Replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  year={2016},
  booktitle = {International Conference on Learning Representations}
}


@article{gruslys2017reactor,
  title={The Reactor: A Sample-Efficient Actor-Critic Architecture},
  author={Gruslys, Audrunas and Azar, Mohammad Gheshlaghi and Bellemare, Marc G and Munos, Remi},
  journal={arXiv preprint arXiv:1704.04651},
  year={2017}
}


@inproceedings{zimmer2016neural,
  title={Neural fitted actor-critic},
  author={Zimmer, Matthieu and Boniface, Yann and Dutech, Alain},
  booktitle={European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2016)},
  year={2016}
}


@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}



@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}



@inproceedings{gu2017q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  booktitle = {International Conference on Learning Representations},
  year={2017}
}


@inproceedings{lillicrap2016continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle = {International Conference on Learning Representations},
  year={2016}
}



@article{heusel2017gans,
  title={GANs trained by a two-time-scale update rule converge to a Nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Klambauer, G{\"u}nter and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1706.08500},
  year={2017}
}

@inproceedings{daskalakis2018limit,
  title={The limit points of (optimistic) gradient descent in min-max optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9236--9246},
  year={2018}
}






@article{mazumdar2018convergence,
  title={On the Convergence of Competitive, Multi-Agent Gradient-Based Learning},
  author={Mazumdar, Eric and Ratliff, Lillian J},
  journal={arXiv preprint arXiv:1804.05464},
  year={2018}
}

@article{mazumdar2019finding,
  title={On finding local nash equilibria (and only local nash equilibria) in zero-sum games},
  author={Mazumdar, Eric V and Jordan, Michael I and Sastry, S Shankar},
  journal={arXiv preprint arXiv:1901.00838},
  year={2019}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{zhou2017mirror,
  title={Mirror descent learning in continuous games},
  author={Zhou, Zhengyuan and Mertikopoulos, Panayotis and Moustakas, Aris L and Bambos, Nicholas and Glynn, Peter},
  booktitle={Conference on Decision and Control (CDC)},
  pages={5776--5783},
  year={2017},
  organization={IEEE}
}


@article{gao2018passivity,
  title={On Passivity, Reinforcement Learning and Higher-Order Learning in Multi-Agent Finite Games},
  author={Gao, Bolin and Pavel, Lacra},
  journal={arXiv preprint arXiv:1808.04464},
  year={2018}
}


@inproceedings{gidel2018variational,
  title={A variational inequality perspective on generative adversarial networks},
  author={Gidel, Gauthier and Berard, Hugo and Vignoud, Ga{\"e}tan and Vincent, Pascal and Lacoste-Julien, Simon},
  booktitle={International Conference on Learning Representations}, 
  year={2019}
}

@inproceedings{singh2000nash,
  title={Nash convergence of gradient dynamics in general-sum games},
  author={Singh, Satinder and Kearns, Michael and Mansour, Yishay},
  booktitle={Uncertainty in artificial intelligence},
  pages={541--548},
  year={2000},
  organization={Morgan Kaufmann Publishers Inc.}
}


@article{silver2017mastering2,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}


@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {\url{https://blog.openai.com/openai-five/}},
      year = {2018}}

@misc{alphastarblog,
  title="{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}",
  author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
  howpublished={\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
  year={2019}
}



@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}



@article{nash1951non,
  title={Non-cooperative games},
  author={Nash, John},
  journal={Annals of mathematics},
  pages={286--295},
  year={1951},
  publisher={JSTOR}
}


@article{bowlingrational,
  title={Rational and Convergent Learning in Stochastic Games},
  author={Bowling, Michael and Veloso, Manuela}
}


@inproceedings{perolat2018actor,
  title={Actor-critic fictitious play in simultaneous move multistage games},
  author={P{\'e}rolat, Julien and Piot, Bilal and Pietquin, Olivier},
  booktitle={AISTATS 2018-21st International Conference on Artificial Intelligence and Statistics},
  year={2018}
}


@article{gao2018adversarial,
  title={Adversarial Policy Gradient for Alternating Markov Games},
  author={Gao, Chao and Mueller, Martin and Hayward, Ryan},
  year={2018}
}


@article{zou2019finite,
  title={Finite-Sample Analysis for SARSA and Q-Learning with Linear Function Approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  journal={arXiv preprint arXiv:1902.02234},
  year={2019}
}

@inproceedings{li2019robust,
  title={Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradient},
  author={Li, Shihui and Wu, Yi and Cui, Xinyue and Dong, Honghua and Fang, Fei and Russell, Stuart},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2019}
}


@article{littman2001value,
  title={Value-function reinforcement learning in Markov games},
  author={Littman, Michael L},
  journal={Cognitive Systems Research},
  volume={2},
  number={1},
  pages={55--66},
  year={2001},
  publisher={Elsevier}
}



@inproceedings{banerjee2003adaptive,
  title={Adaptive policy gradient in multiagent learning},
  author={Banerjee, Bikramjit and Peng, Jing},
  booktitle={Conference on Autonomous Agents and Multiagent Systems},
  pages={686--692},
  year={2003},
  organization={ACM}
}

@article{cai2019global,
  title={On the Global Convergence of Imitation Learning: A Case for Linear Quadratic Regulator},
  author={Cai, Qi and Hong, Mingyi and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1901.03674},
  year={2019}
}



@article{murty1987some,
  title={Some NP-complete problems in quadratic and nonlinear programming},
  author={Murty, Katta G and Kabadi, Santosh N},
  journal={Mathematical programming},
  volume={39},
  number={2},
  pages={117--129},
  year={1987},
  publisher={Springer}
}

@inproceedings{balduzzi2018mechanics,
  title={The Mechanics of n-Player Differentiable Games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  booktitle={International Conference on Machine Learning},
  pages={363--372},
  year={2018}
}


@article{malik2018derivative,
  title={Derivative-free methods for policy optimization: Guarantees for linear quadratic systems},
  author={Malik, Dhruv and Pananjady, Ashwin and Bhatia, Kush and Khamaru, Koulik and Bartlett, Peter L and Wainwright, Martin J},
  journal={arXiv preprint arXiv:1812.08305},
  year={2018}
}

@article{jin2019minmax,
  title={Minmax Optimization: {S}table Limit Points of Gradient Descent Ascent are Locally Optimal},
  author={Jin, Chi and Netrapalli, Praneeth and Jordan, Michael I},
  journal={arXiv preprint arXiv:1902.00618},
  year={2019}
}


@article{tu2018gap,
  title={The gap between model-based and model-free methods on the linear quadratic regulator: An asymptotic viewpoint},
  author={Tu, Stephen and Recht, Benjamin},
  journal={arXiv preprint arXiv:1812.03565},
  year={2018}
}

@article{conitzer2007awesome,
  title={AWESOME: A general multiagent learning algorithm that converges in self-play and learns a best response against stationary opponents},
  author={Conitzer, Vincent and Sandholm, Tuomas},
  journal={Machine Learning},
  volume={67},
  number={1-2},
  pages={23--43},
  year={2007},
  publisher={Springer}
}


@article{zhang2018finite,
  title={Finite-sample analyses for fully decentralized multi-agent reinforcement learning},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Ba{\c{s}}ar, Tamer},
  journal={arXiv preprint arXiv:1812.02783},
  year={2018}
}



@inproceedings{littman2001friend,
  title={Friend-or-Foe Q-learning in General-Sum Games},
  author={Littman, Michael L},
  booktitle={Proceedings of the Eighteenth International Conference on Machine Learning},
  pages={322--328},
  year={2001},
  organization={Morgan Kaufmann Publishers Inc.}
}

@article{yang2019theoretical,
  title={A Theoretical Analysis of Deep {Q}-Learning},
  author={Yang, Zhuora and Xie, Yuchen and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1901.00137},
  year={2019}
}
@inproceedings{perolat2016use,
  title={On the Use of Non-Stationary Strategies for Solving Two-Player Zero-Sum Markov Games},
  author={P{\'e}rolat, Julien and Piot, Bilal and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={Conference on Artificial Intelligence and Statistics},
  year={2016}
}


@inproceedings{lagoudakis2002value,
  title={Value function approximation in zero-sum markov games},
  author={Lagoudakis, Michail G and Parr, Ronald},
  booktitle={Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence},
  pages={283--292},
  year={2002},
  organization={Morgan Kaufmann Publishers Inc.}
}


@inproceedings{perolat2016softened,
  title={Softened approximate policy iteration for Markov games},
  author={P{\'e}rolat, Julien and Piot, Bilal and Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  year={2016}
}

@inproceedings{perolat2015approximate,
  title={Approximate dynamic programming for two-player zero-sum markov games},
  author={Perolat, Julien and Scherrer, Bruno and Piot, Bilal and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning (ICML 2015)},
  year={2015}
}
 

@inproceedings{srinivasan2018actor,
  title={Actor-critic policy optimization in partially observable multiagent environments},
  author={Srinivasan, Sriram and Lanctot, Marc and Zambaldi, Vinicius and P{\'e}rolat, Julien and Tuyls, Karl and Munos, R{\'e}mi and Bowling, Michael},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3422--3435},
  year={2018}
}