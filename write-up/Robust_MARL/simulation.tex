

\section{Simulation}\label{sec:sim}


In this section, we provide simulation results to evaluate the performance of the proposed algorithms. 


\issue{
Simulation TO-DOs:
\begin{itemize}
	\item We test the algorithms on two platforms: MADDPG environment and DeepRacer. 
	\item For the MADDPG environment, we need to:
	\begin{itemize}
	\item Change both the transition dynamics $\bar P(\cdot\given s,\cdot)$ and the reward function  $\bar\cR^i_s$ for each agent $i$ and state $s$, in order to get the robust MARL environment.  
	\item Test both the Q-learning and the actor-critic (MADDPG-based, namely, Algorithm \ref{alg:batch_AC}) algorithms, using MADDPG as a baseline. 
	\end{itemize}
\end{itemize}
}



